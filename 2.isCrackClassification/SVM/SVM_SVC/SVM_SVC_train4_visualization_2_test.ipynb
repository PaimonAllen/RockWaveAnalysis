{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对于SVM，存在一个分类面，两个点集到此平面的最小距离最大，两个点集中的边缘点到此平面的距离最大。\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import colors\n",
    "from sklearn import svm \n",
    "from sklearn import model_selection\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22765, 4)\n",
      "(22765, 1)\n",
      "(9757, 4)\n",
      "(9757, 1)\n"
     ]
    }
   ],
   "source": [
    "# *************将字符串转为整型，便于数据加载***********************\n",
    "# 在函数中建立一个对应字典就可以了，输入字符串，输出字符串对应的数字。\n",
    "def rock_type(s):\n",
    "    #     print(type(s))\n",
    "    # 字符串加个b是指btypes 字节串类型\n",
    "    it = {b'circle': 0, b'square': 1}\n",
    "    return it[s]\n",
    "\n",
    "\n",
    "# 加载数据\n",
    "data_path = '../dataset/train4/train4.txt'  # 数据文件的路径\n",
    "data = np.loadtxt(data_path,  # 数据文件路径\n",
    "                  dtype=float,  # 数据类型\n",
    "                  delimiter=','  # 数据分隔符\n",
    "                #   converters={2: rock_type}\n",
    "                  )  # 将第5列使用函数iris_type进行转换\n",
    "# print(data)                                                 #data为二维数组，data.shape=(150, 5)\n",
    "# print(data.shape)\n",
    "# 数据分割\n",
    "x, y = np.split(data,  # 要切分的数组\n",
    "                (4,),  # 沿轴切分的位置，第3列开始往后为y\n",
    "                axis=1)  # 1代表纵向分割，按列分割\n",
    "\n",
    "x = x[:, 0:4]\n",
    "# 第一个逗号之前表示行，只有冒号表示所有行，第二个冒号0:2表是0,1两列\n",
    "# 在X中我们取前两列作为特征，为了后面的可视化，原始的四维不好画图。x[:,0:4]代表第一维(行)全取，第二维(列)取0~2\n",
    "# print(x)\n",
    "x_train, x_test, y_train, y_test = model_selection.train_test_split(\n",
    "    x,  # 所要划分的样本特征集\n",
    "    y,  # 所要划分的样本结果\n",
    "    random_state=1,  # 随机数种子确保产生的随机数组相同\n",
    "    test_size=0.3)  # 测试样本占比\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model\n",
    "# **********************SVM分类器构建*************************\n",
    "def classifier():\n",
    "    #clf = svm.SVC(C=0.8,kernel='rbf', gamma=50,decision_function_shape='ovr')\n",
    "    clf = svm.SVC(C=0.5,  # 误差项惩罚系数,默认值是1\n",
    "                  kernel='rbf',  # 线性核 kenrel=\"rbf\":高斯核\n",
    "                  decision_function_shape='ovr')  # 决策函数\n",
    "    return clf\n",
    "\n",
    "\n",
    "# 2.定义模型：SVM模型定义\n",
    "clf = classifier()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.51313066e+00 -1.91500843e+00  2.75018700e-05 ... -1.58011031e+00\n",
      "  1.22643052e-05  3.08106279e+00]\n"
     ]
    }
   ],
   "source": [
    "y_train.ravel()  # ravel()扁平化，将原来的二维数组转换为一维数组\n",
    "print(x_train.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型训练\n",
    "\n",
    "# y_train.ravel()  # ravel()扁平化，将原来的二维数组转换为一维数组\n",
    "# ***********************训练模型*****************************\n",
    "\n",
    "\n",
    "def train(clf, x_train, y_train):\n",
    "    clf.fit(x_train,  # 训练集特征向量，fit表示输入数据开始拟合\n",
    "            y_train.ravel())  # 训练集目标值 ravel()扁平化，将原来的二维数组转换为一维数组\n",
    "\n",
    "\n",
    "# 3.训练SVM模型\n",
    "train(clf, x_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trianing prediction:0.936\n",
      "test data prediction:0.931\n",
      "traing data Accuracy:0.936\n",
      "testing data Accuracy:0.931\n",
      "decision_function:\n",
      " [ 0.33319591  0.55378586  3.00058524 ...  0.89028037 -4.50194314\n",
      " -3.23208119]\n"
     ]
    }
   ],
   "source": [
    "# **************并判断a b是否相等，计算acc的均值*************\n",
    "def show_accuracy(a, b, tip):\n",
    "    acc = a.ravel() == b.ravel()\n",
    "    print('%s Accuracy:%.3f' % (tip, np.mean(acc)))\n",
    "\n",
    "\n",
    "def print_accuracy(clf, x_train, y_train, x_test, y_test):\n",
    "    # 分别打印训练集和测试集的准确率  score(x_train,y_train):表示输出x_train,y_train在模型上的准确率\n",
    "    print('trianing prediction:%.3f' % (clf.score(x_train, y_train)))\n",
    "    print('test data prediction:%.3f' % (clf.score(x_test, y_test)))\n",
    "    # 原始结果与预测结果进行对比   predict()表示对x_train样本进行预测，返回样本类别\n",
    "    show_accuracy(clf.predict(x_train), y_train, 'traing data')\n",
    "    show_accuracy(clf.predict(x_test), y_test, 'testing data')\n",
    "    # 计算决策函数的值，表示x到各分割平面的距离,3类，所以有3个决策函数，不同的多类情况有不同的决策函数？\n",
    "    print('decision_function:\\n', clf.decision_function(x_train))\n",
    "\n",
    "\n",
    "# 4.模型评估\n",
    "print_accuracy(clf, x_train, y_train, x_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.5405314  1.31828082 1.4583292  ... 1.5861994  1.93632007 1.36394882]\n",
      "(9757, 4)\n"
     ]
    }
   ],
   "source": [
    "print(x[:, 0])\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32522, 5)\n",
      "(9757, 5)\n",
      "(3000, 2)\n",
      "(3000, 1)\n",
      "(1000, 2)\n",
      "(1000, 1)\n"
     ]
    }
   ],
   "source": [
    "# 取样，取10%，不然数据太多了看不清\n",
    "# https://blog.csdn.net/weixin_42201701/article/details/86655721\n",
    "\n",
    "# x_random =[]\n",
    "# for i in range(0,300):\n",
    "#        x_random.append(np.random.choice(x.shape[0],1))\n",
    "# x_random = x.copy()\n",
    "# np.random.shuffle(x_random)\n",
    "# x_plot = x_random[:300, :]\n",
    "\n",
    "# x_test_random = x.copy()\n",
    "# np.random.shuffle(x_test_random)\n",
    "# x_test_plot = x_test_random[:300, :]\n",
    "\n",
    "# y_random = y.copy()\n",
    "# np.random.shuffle(y_random)\n",
    "# y_plot = y_random[:300, :]\n",
    "# x_test_random = np.random.choice(x.shape[0],300)\n",
    "# y_random = np.random.choice(x.shape[0],300)\n",
    "\n",
    "# x_plot = x[row_rand_array1[0:300]]\n",
    "\n",
    "# row_rand_array = np.arange(x_test.shape[0])\n",
    "\n",
    "# np.random.choice(row_rand_array)\n",
    "\n",
    "# x_test_plot = x_test[row_rand_array[0:300]]\n",
    "\n",
    "# y_plot = np.random.choice(y.flatten(), size=300)\n",
    "\n",
    "nums1=3000\n",
    "nums2=1000\n",
    "\n",
    "total_x=np.hstack((x,y))\n",
    "total_x_test=np.hstack((x_test,y_test))\n",
    "\n",
    "\n",
    "x_random = total_x.copy()\n",
    "np.random.shuffle(x_random)\n",
    "x_plot = x_random[:nums1, :2]\n",
    "y_plot = x_random[:nums1, 2:3]\n",
    "\n",
    "x_test_random = total_x_test.copy()\n",
    "np.random.shuffle(x_test_random)\n",
    "x_test_plot = x_test_random[:nums2, :2]\n",
    "y_test_plot= x_test_random[:nums2, 2:3]\n",
    "\n",
    "print(total_x.shape)\n",
    "print(total_x_test.shape)\n",
    "print(x_plot.shape)\n",
    "print(y_plot.shape)\n",
    "print(x_test_plot.shape)\n",
    "print(y_test_plot.shape)\n",
    "# print(y_plot)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grid_test:\n",
      " [[ 1.0637583  -2.59567818 -2.59567818]\n",
      " [ 1.0637583  -2.59567818 -2.58856189]\n",
      " [ 1.0637583  -2.59567818 -2.5814456 ]\n",
      " ...\n",
      " [ 2.56531961 -1.17953733 -1.1937699 ]\n",
      " [ 2.56531961 -1.17953733 -1.18665362]\n",
      " [ 2.56531961 -1.17953733 -1.17953733]]\n",
      "(8000000, 3)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "X has 3 features, but SVC is expecting 4 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/tzr/DataLinux/Documents/GitHubSYNC/RockWaveAnalysis/2.isCrackClassification/SVM/SVM_SVC/SVM_SVC_train4_visualization_2_test.ipynb Cell 9\u001b[0m in \u001b[0;36m<cell line: 58>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a226c696e7578536572766572284c414e2928426c756529227d/home/tzr/DataLinux/Documents/GitHubSYNC/RockWaveAnalysis/2.isCrackClassification/SVM/SVM_SVC/SVM_SVC_train4_visualization_2_test.ipynb#ch0000008vscode-remote?line=53'>54</a>\u001b[0m     plt\u001b[39m.\u001b[39mshow()\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a226c696e7578536572766572284c414e2928426c756529227d/home/tzr/DataLinux/Documents/GitHubSYNC/RockWaveAnalysis/2.isCrackClassification/SVM/SVM_SVC/SVM_SVC_train4_visualization_2_test.ipynb#ch0000008vscode-remote?line=56'>57</a>\u001b[0m \u001b[39m# 5.模型使用\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a226c696e7578536572766572284c414e2928426c756529227d/home/tzr/DataLinux/Documents/GitHubSYNC/RockWaveAnalysis/2.isCrackClassification/SVM/SVM_SVC/SVM_SVC_train4_visualization_2_test.ipynb#ch0000008vscode-remote?line=57'>58</a>\u001b[0m draw(clf, x)\n",
      "\u001b[1;32m/home/tzr/DataLinux/Documents/GitHubSYNC/RockWaveAnalysis/2.isCrackClassification/SVM/SVM_SVC/SVM_SVC_train4_visualization_2_test.ipynb Cell 9\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(clf, x)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a226c696e7578536572766572284c414e2928426c756529227d/home/tzr/DataLinux/Documents/GitHubSYNC/RockWaveAnalysis/2.isCrackClassification/SVM/SVM_SVC/SVM_SVC_train4_visualization_2_test.ipynb#ch0000008vscode-remote?line=15'>16</a>\u001b[0m \u001b[39mprint\u001b[39m(grid_test\u001b[39m.\u001b[39mshape)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a226c696e7578536572766572284c414e2928426c756529227d/home/tzr/DataLinux/Documents/GitHubSYNC/RockWaveAnalysis/2.isCrackClassification/SVM/SVM_SVC/SVM_SVC_train4_visualization_2_test.ipynb#ch0000008vscode-remote?line=16'>17</a>\u001b[0m \u001b[39m# 输出样本到决策面的距离\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a226c696e7578536572766572284c414e2928426c756529227d/home/tzr/DataLinux/Documents/GitHubSYNC/RockWaveAnalysis/2.isCrackClassification/SVM/SVM_SVC/SVM_SVC_train4_visualization_2_test.ipynb#ch0000008vscode-remote?line=17'>18</a>\u001b[0m z \u001b[39m=\u001b[39m clf\u001b[39m.\u001b[39;49mdecision_function(grid_test)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a226c696e7578536572766572284c414e2928426c756529227d/home/tzr/DataLinux/Documents/GitHubSYNC/RockWaveAnalysis/2.isCrackClassification/SVM/SVM_SVC/SVM_SVC_train4_visualization_2_test.ipynb#ch0000008vscode-remote?line=18'>19</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mthe distance to decision plane:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m'\u001b[39m, z)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a226c696e7578536572766572284c414e2928426c756529227d/home/tzr/DataLinux/Documents/GitHubSYNC/RockWaveAnalysis/2.isCrackClassification/SVM/SVM_SVC/SVM_SVC_train4_visualization_2_test.ipynb#ch0000008vscode-remote?line=20'>21</a>\u001b[0m \u001b[39m# 预测分类值 得到【0,0.。。。1,1,1】\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/KNN/lib/python3.9/site-packages/sklearn/svm/_base.py:775\u001b[0m, in \u001b[0;36mBaseSVC.decision_function\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    748\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecision_function\u001b[39m(\u001b[39mself\u001b[39m, X):\n\u001b[1;32m    749\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Evaluate the decision function for the samples in X.\u001b[39;00m\n\u001b[1;32m    750\u001b[0m \n\u001b[1;32m    751\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    773\u001b[0m \u001b[39m    transformation of ovo decision function.\u001b[39;00m\n\u001b[1;32m    774\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 775\u001b[0m     dec \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_decision_function(X)\n\u001b[1;32m    776\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdecision_function_shape \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39movr\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclasses_) \u001b[39m>\u001b[39m \u001b[39m2\u001b[39m:\n\u001b[1;32m    777\u001b[0m         \u001b[39mreturn\u001b[39;00m _ovr_decision_function(dec \u001b[39m<\u001b[39m \u001b[39m0\u001b[39m, \u001b[39m-\u001b[39mdec, \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclasses_))\n",
      "File \u001b[0;32m~/anaconda3/envs/KNN/lib/python3.9/site-packages/sklearn/svm/_base.py:533\u001b[0m, in \u001b[0;36mBaseLibSVM._decision_function\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    519\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Evaluates the decision function for the samples in X.\u001b[39;00m\n\u001b[1;32m    520\u001b[0m \n\u001b[1;32m    521\u001b[0m \u001b[39mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    529\u001b[0m \u001b[39m    in the model.\u001b[39;00m\n\u001b[1;32m    530\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    531\u001b[0m \u001b[39m# NOTE: _validate_for_predict contains check for is_fitted\u001b[39;00m\n\u001b[1;32m    532\u001b[0m \u001b[39m# hence must be placed before any other attributes are used.\u001b[39;00m\n\u001b[0;32m--> 533\u001b[0m X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_for_predict(X)\n\u001b[1;32m    534\u001b[0m X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compute_kernel(X)\n\u001b[1;32m    536\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sparse:\n",
      "File \u001b[0;32m~/anaconda3/envs/KNN/lib/python3.9/site-packages/sklearn/svm/_base.py:611\u001b[0m, in \u001b[0;36mBaseLibSVM._validate_for_predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    608\u001b[0m check_is_fitted(\u001b[39mself\u001b[39m)\n\u001b[1;32m    610\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m callable(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkernel):\n\u001b[0;32m--> 611\u001b[0m     X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(\n\u001b[1;32m    612\u001b[0m         X,\n\u001b[1;32m    613\u001b[0m         accept_sparse\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mcsr\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    614\u001b[0m         dtype\u001b[39m=\u001b[39;49mnp\u001b[39m.\u001b[39;49mfloat64,\n\u001b[1;32m    615\u001b[0m         order\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mC\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    616\u001b[0m         accept_large_sparse\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    617\u001b[0m         reset\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    618\u001b[0m     )\n\u001b[1;32m    620\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sparse \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m sp\u001b[39m.\u001b[39misspmatrix(X):\n\u001b[1;32m    621\u001b[0m     X \u001b[39m=\u001b[39m sp\u001b[39m.\u001b[39mcsr_matrix(X)\n",
      "File \u001b[0;32m~/anaconda3/envs/KNN/lib/python3.9/site-packages/sklearn/base.py:600\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    597\u001b[0m     out \u001b[39m=\u001b[39m X, y\n\u001b[1;32m    599\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m check_params\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mensure_2d\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mTrue\u001b[39;00m):\n\u001b[0;32m--> 600\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_check_n_features(X, reset\u001b[39m=\u001b[39;49mreset)\n\u001b[1;32m    602\u001b[0m \u001b[39mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m~/anaconda3/envs/KNN/lib/python3.9/site-packages/sklearn/base.py:400\u001b[0m, in \u001b[0;36mBaseEstimator._check_n_features\u001b[0;34m(self, X, reset)\u001b[0m\n\u001b[1;32m    397\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m    399\u001b[0m \u001b[39mif\u001b[39;00m n_features \u001b[39m!=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_features_in_:\n\u001b[0;32m--> 400\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    401\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mX has \u001b[39m\u001b[39m{\u001b[39;00mn_features\u001b[39m}\u001b[39;00m\u001b[39m features, but \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    402\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mis expecting \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_features_in_\u001b[39m}\u001b[39;00m\u001b[39m features as input.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    403\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: X has 3 features, but SVC is expecting 4 features as input."
     ]
    }
   ],
   "source": [
    "# 可视化及使用\n",
    "# 所有数据\n",
    "def draw(clf, x):\n",
    "    # 标记特征值\n",
    "    iris_feature = u'Amp1', u'Amp2',u'mean',u'range'\n",
    "    # 开始画图\n",
    "    x1_min, x1_max = x[:, 0].min()-(x[:, 0].max())/10, x[:, 0].max()+ (x[:, 0].max())/10 # 第0列的范围\n",
    "    x2_min, x2_max = x[:, 1].min()-abs((x[:, 1].max())/7), x[:, 1].max()+abs((x[:, 1].max())/7)  # 第1列的范围\n",
    "    x3_min, x3_max = x[:, 1].min()-abs((x[:, 1].max())/7), x[:, 1].max()+abs((x[:, 1].max())/7)  # 第1列的范围\n",
    "    # 生成网格采样点 开始坐标：结束坐标（不包括）：步长\n",
    "    x1, x2, x3 = np.mgrid[x1_min:x1_max:200j, x2_min:x2_max:200j,x3_min:x3_max:200j]\n",
    "    # flat将二维数组转换成1个1维的迭代器，然后把x1和x2的所有可能值给匹配成为样本点\n",
    "    # stack():沿着新的轴加入一系列数组，竖着（按列）增加两个数组，grid_test的shape：(40000, 2)\n",
    "    grid_test = np.stack((x1.flat, x2.flat, x3.flat), axis=1)\n",
    "    print('grid_test:\\n', grid_test)\n",
    "    print(grid_test.shape)\n",
    "    # 输出样本到决策面的距离\n",
    "    z = clf.decision_function(grid_test)\n",
    "    print('the distance to decision plane:\\n', z)\n",
    "\n",
    "    # 预测分类值 得到【0,0.。。。1,1,1】\n",
    "    grid_hat = clf.predict(grid_test)\n",
    "    print('grid_hat:\\n', grid_hat)\n",
    "    # reshape grid_hat和x1形状一致\n",
    "    grid_hat = grid_hat.reshape(x1.shape)\n",
    "    # 若3*3矩阵e，则e.shape()为3*3,表示3行3列\n",
    "    # light是网格测试点的配色，相当于背景\n",
    "    # dark是样本点的配色\n",
    "    cm_light = mpl.colors.ListedColormap(['#00FFCC', '#FFA0A0', '#A0A0FF'])\n",
    "    cm_dark = mpl.colors.ListedColormap(['g', 'b'])\n",
    "    cm_test = mpl.colors.ListedColormap(['r', 'm'])\n",
    "    # 画出所有网格样本点被判断为的分类，作为背景\n",
    "    # pcolormesh(x,y,z,cmap)这里参数代入\n",
    "    plt.pcolormesh(x1, x2, grid_hat, cmap=cm_light)\n",
    "    # x1，x2，grid_hat，cmap=cm_light绘制的是背景。\n",
    "    # squeeze()把y的个数为1的维度去掉，也就是变成一维。\n",
    "    # 所有数据\n",
    "    \n",
    "    plt.scatter(x[:, 0], x[:, 1], x[:, 2] ,c=np.squeeze(\n",
    "        y), edgecolor='k', s=50, cmap=cm_dark)  # 样本点\n",
    "    # plt.scatter(x_test[:, 0], x_test[:, 1], s=1,\n",
    "    #             facecolor='red', zorder=10, marker='+')       # 测试点\n",
    "    plt.scatter(x_test[:, 0], x_test[:, 1], x_test[:, 2],c=np.squeeze(\n",
    "        y_test), marker='+', zorder=10, s=20, cmap=cm_test)       # 测试点\n",
    "  \n",
    "    # 设置坐标标签及字体大小\n",
    "    plt.xlabel(iris_feature[2], fontsize=13)\n",
    "    plt.ylabel(iris_feature[3], fontsize=13)\n",
    "    plt.xlim(x1_min, x1_max)\n",
    "    plt.ylim(x2_min, x2_max)\n",
    "    plt.title('SVM classification for rock', fontsize=16)\n",
    "    plt.grid()\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# 5.模型使用\n",
    "draw(clf, x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 可视化及使用\n",
    "# 所有数据\n",
    "def draw(clf, x):\n",
    "    # 标记特征值\n",
    "    iris_feature = u'Amp1', u'Amp2',u'mean',u'range'\n",
    "    # 开始画图\n",
    "    x1_min, x1_max = x[:, 0].min()-(x[:, 0].max())/10, x[:, 0].max()+ (x[:, 0].max())/10 # 第0列的范围\n",
    "    x2_min, x2_max = x[:, 1].min()-abs((x[:, 1].max())/7), x[:, 1].max()+abs((x[:, 1].max())/7)  # 第1列的范围\n",
    "    x3_min, x3_max = x[:, 1].min()-abs((x[:, 1].max())/7), x[:, 1].max()+abs((x[:, 1].max())/7)  # 第1列的范围\n",
    "    # 生成网格采样点 开始坐标：结束坐标（不包括）：步长\n",
    "    x1, x2, x3 = np.mgrid[x1_min:x1_max:200j, x2_min:x2_max:200j,x3_min:x3_max:200j]\n",
    "    # flat将二维数组转换成1个1维的迭代器，然后把x1和x2的所有可能值给匹配成为样本点\n",
    "    # stack():沿着新的轴加入一系列数组，竖着（按列）增加两个数组，grid_test的shape：(40000, 2)\n",
    "    grid_test = np.stack((x1.flat, x2.flat, x3.flat), axis=1)\n",
    "    print('grid_test:\\n', grid_test)\n",
    "    print(grid_test.shape)\n",
    "    # 输出样本到决策面的距离\n",
    "    z = clf.decision_function(grid_test)\n",
    "    print('the distance to decision plane:\\n', z)\n",
    "\n",
    "    # 预测分类值 得到【0,0.。。。1,1,1】\n",
    "    grid_hat = clf.predict(grid_test)\n",
    "    print('grid_hat:\\n', grid_hat)\n",
    "    # reshape grid_hat和x1形状一致\n",
    "    grid_hat = grid_hat.reshape(x1.shape)\n",
    "    # 若3*3矩阵e，则e.shape()为3*3,表示3行3列\n",
    "    # light是网格测试点的配色，相当于背景\n",
    "    # dark是样本点的配色\n",
    "    cm_light = mpl.colors.ListedColormap(['#00FFCC', '#FFA0A0', '#A0A0FF'])\n",
    "    cm_dark = mpl.colors.ListedColormap(['g', 'b'])\n",
    "    cm_test = mpl.colors.ListedColormap(['r', 'm'])\n",
    "    # 画出所有网格样本点被判断为的分类，作为背景\n",
    "    # pcolormesh(x,y,z,cmap)这里参数代入\n",
    "    plt.pcolormesh(x1, x2, grid_hat, cmap=cm_light)\n",
    "    # x1，x2，grid_hat，cmap=cm_light绘制的是背景。\n",
    "    # squeeze()把y的个数为1的维度去掉，也就是变成一维。\n",
    "    # 所有数据\n",
    "    \n",
    "    plt.scatter(x_plot[:, 0], x_plot[:, 1], x_plot[:, 2] ,c=np.squeeze(\n",
    "        y_plot), edgecolor='k', s=50, cmap=cm_dark)  # 样本点\n",
    "    # plt.scatter(x_test[:, 0], x_test[:, 1], s=1,\n",
    "    #             facecolor='red', zorder=10, marker='+')       # 测试点\n",
    "    plt.scatter(x_test_plot[:, 0], x_test_plot[:, 1], x_test_plot[:, 2],c=np.squeeze(\n",
    "        y_test_plot), marker='+', zorder=10, s=20, cmap=cm_test)       # 测试点\n",
    "  \n",
    "    # 设置坐标标签及字体大小\n",
    "    plt.xlabel(iris_feature[2], fontsize=13)\n",
    "    plt.ylabel(iris_feature[3], fontsize=13)\n",
    "    plt.xlim(x1_min, x1_max)\n",
    "    plt.ylim(x2_min, x2_max)\n",
    "    plt.title('SVM classification for rock', fontsize=16)\n",
    "    plt.grid()\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# 5.模型使用\n",
    "draw(clf, x)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('KNN')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b5b752daff17e0bf69700663140c99ce1d03e57d78592962b9d45988231c70e3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
